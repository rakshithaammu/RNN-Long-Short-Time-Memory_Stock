{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee1d788a-a376-48b1-b38a-67c2903b1c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout # GRU, Bidirectional\n",
    "#from keras.optimizer import SGD\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7a420f7-65c8-4356-8f29-5647d6b8ebba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-03</th>\n",
       "      <td>82.45</td>\n",
       "      <td>82.55</td>\n",
       "      <td>80.81</td>\n",
       "      <td>82.06</td>\n",
       "      <td>11715200</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-04</th>\n",
       "      <td>82.20</td>\n",
       "      <td>82.50</td>\n",
       "      <td>81.33</td>\n",
       "      <td>81.95</td>\n",
       "      <td>9840600</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-05</th>\n",
       "      <td>81.40</td>\n",
       "      <td>82.90</td>\n",
       "      <td>81.00</td>\n",
       "      <td>82.50</td>\n",
       "      <td>7213500</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-06</th>\n",
       "      <td>83.95</td>\n",
       "      <td>85.03</td>\n",
       "      <td>83.41</td>\n",
       "      <td>84.95</td>\n",
       "      <td>8197400</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-09</th>\n",
       "      <td>84.10</td>\n",
       "      <td>84.25</td>\n",
       "      <td>83.38</td>\n",
       "      <td>83.73</td>\n",
       "      <td>6858200</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open   High    Low  Close    Volume Name\n",
       "Date                                                 \n",
       "2006-01-03  82.45  82.55  80.81  82.06  11715200  IBM\n",
       "2006-01-04  82.20  82.50  81.33  81.95   9840600  IBM\n",
       "2006-01-05  81.40  82.90  81.00  82.50   7213500  IBM\n",
       "2006-01-06  83.95  85.03  83.41  84.95   8197400  IBM\n",
       "2006-01-09  84.10  84.25  83.38  83.73   6858200  IBM"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\raksh\\Downloads\\IBM_2006-01-01_to_2018-01-01.csv\", index_col='Date', parse_dates=['Date'])\n",
    "data.head() #view first five columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "462482be-0838-4948-9e7f-248083e19af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytrain = data[:'2016'].iloc[:,1:2].values #selecting all rows upto 2016 and selecting column 1\n",
    "mytest = data['2017':].iloc[:,1:2].values #Tries to predict all rows after 2017 and selecting column 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f77cb15-1fe2-49dc-b728-89d4c389ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the training set\n",
    "sc = MinMaxScaler(feature_range=(0,1)) # MinMaxScaler(feature_range= (start,stop))\n",
    "mytrain_scaled = sc.fit_transform(mytrain) #instance.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7af16cae-202d-47f2-91be-75f60a809376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06065089],\n",
       "       [0.06029868],\n",
       "       [0.06311637],\n",
       "       ...,\n",
       "       [0.66074951],\n",
       "       [0.65546633],\n",
       "       [0.6534235 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytrain_scaled #view the scaled values!\n",
    "#82.55 ==> 0.06065..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e22529b-e25f-498a-b2dc-d449e0563bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2769"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mytrain_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "380dfd1a-faa1-4f2f-9059-67a37698f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "I_train = []\n",
    "O_train = []\n",
    "for i in range(60,2769):\n",
    "    I_train.append(mytrain_scaled[i-60:i,0]) #every sequence will have 60 rows/values as input\n",
    "    O_train.append(mytrain_scaled[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01ec90f9-7ad2-4389-a0f7-9443cc42a08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06065089, 0.06029868, 0.06311637, 0.0781206 , 0.07262609,\n",
       "       0.07171034, 0.07657087, 0.07058326, 0.0669907 , 0.06494787,\n",
       "       0.075796  , 0.07361229, 0.06417301, 0.05621302, 0.05783319,\n",
       "       0.05409975, 0.05431107, 0.05515638, 0.05543815, 0.05677656,\n",
       "       0.05846717, 0.05388842, 0.04811214, 0.04233587, 0.04402649,\n",
       "       0.0490279 , 0.04832347, 0.05297267, 0.05614258, 0.05290223,\n",
       "       0.05325444, 0.04909834, 0.04994365, 0.04797126, 0.05431107,\n",
       "       0.05212736, 0.04726684, 0.04895745, 0.04656241, 0.04839391,\n",
       "       0.04416737, 0.0485348 , 0.04719639, 0.04825303, 0.05395886,\n",
       "       0.05663567, 0.05853762, 0.05959425, 0.06375035, 0.06917442,\n",
       "       0.06889265, 0.06670893, 0.06910397, 0.07783883, 0.07565511,\n",
       "       0.07276698, 0.06889265, 0.0656523 , 0.06656805, 0.06769513])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09eefffb-e857-416c-8be0-240a8163cb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06875176105945335"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "affc8fa2-5cf9-4376-8877-245089f11ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "I_train = np.array(I_train) #converting into arrays!\n",
    "O_train = np.array(O_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ee51708-4da7-472a-9372-69e0ea539c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2709, 60)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I_train.shape #samples,steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1a88d85-ea39-470c-bf9f-b546e723f579",
   "metadata": {},
   "outputs": [],
   "source": [
    "I_train= I_train.reshape(2709,60,1)\n",
    "#no. of sequences, inputs in every sequence, no. of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b99a284-1e37-435e-a683-5ee7bc4f5dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2709, 60, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92e25915-20c8-4d8b-b572-bef4bd15edc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raksh\\anaconda4\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#building the model\n",
    "\n",
    "model = Sequential()\n",
    "# first LSTM layer\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(I_train.shape[1],1)))\n",
    "model.add(Dropout(0.2))\n",
    "# second LSTM layer\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "# third LSTM layer\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "# fourth LSTM layer\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "# the output layer\n",
    "model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3dbf86a1-5b47-4d65-a2b5-cee193a04136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile\n",
    "model.compile(optimizer='rmsprop',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68de197e-f4cf-4ab1-9db4-236aa42d745f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 98ms/step - loss: 0.0494\n",
      "Epoch 2/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - loss: 0.0108\n",
      "Epoch 3/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - loss: 0.0085\n",
      "Epoch 4/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 101ms/step - loss: 0.0074\n",
      "Epoch 5/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - loss: 0.0064\n",
      "Epoch 6/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - loss: 0.0063\n",
      "Epoch 7/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - loss: 0.0056\n",
      "Epoch 8/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - loss: 0.0049\n",
      "Epoch 9/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - loss: 0.0046\n",
      "Epoch 10/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - loss: 0.0045\n",
      "Epoch 11/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - loss: 0.0043\n",
      "Epoch 12/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - loss: 0.0036\n",
      "Epoch 13/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - loss: 0.0034\n",
      "Epoch 14/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - loss: 0.0034\n",
      "Epoch 15/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - loss: 0.0037\n",
      "Epoch 16/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - loss: 0.0033\n",
      "Epoch 17/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - loss: 0.0033\n",
      "Epoch 18/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 102ms/step - loss: 0.0029\n",
      "Epoch 19/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 101ms/step - loss: 0.0028\n",
      "Epoch 20/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - loss: 0.0029\n",
      "Epoch 21/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - loss: 0.0027\n",
      "Epoch 22/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - loss: 0.0025\n",
      "Epoch 23/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - loss: 0.0025\n",
      "Epoch 24/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - loss: 0.0024\n",
      "Epoch 25/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 6s/step - loss: 0.0022\n",
      "Epoch 26/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - loss: 0.0024\n",
      "Epoch 27/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 102ms/step - loss: 0.0025\n",
      "Epoch 28/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - loss: 0.0023\n",
      "Epoch 29/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 100ms/step - loss: 0.0022\n",
      "Epoch 30/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 99ms/step - loss: 0.0023\n",
      "Epoch 31/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 100ms/step - loss: 0.0020\n",
      "Epoch 32/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 100ms/step - loss: 0.0020\n",
      "Epoch 33/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - loss: 0.0021\n",
      "Epoch 34/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 100ms/step - loss: 0.0020\n",
      "Epoch 35/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - loss: 0.0022\n",
      "Epoch 36/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 101ms/step - loss: 0.0019\n",
      "Epoch 37/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - loss: 0.0019\n",
      "Epoch 38/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - loss: 0.0017\n",
      "Epoch 39/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 100ms/step - loss: 0.0020\n",
      "Epoch 40/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 100ms/step - loss: 0.0019\n",
      "Epoch 41/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - loss: 0.0019\n",
      "Epoch 42/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - loss: 0.0017\n",
      "Epoch 43/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - loss: 0.0017\n",
      "Epoch 44/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - loss: 0.0018\n",
      "Epoch 45/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - loss: 0.0016\n",
      "Epoch 46/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - loss: 0.0018\n",
      "Epoch 47/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 102ms/step - loss: 0.0015\n",
      "Epoch 48/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 99ms/step - loss: 0.0016\n",
      "Epoch 49/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 103ms/step - loss: 0.0016\n",
      "Epoch 50/50\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 101ms/step - loss: 0.0016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b1be96dcd0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(I_train,O_train,epochs=50,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e3cd24e-e54b-4b53-bc20-739822f31218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"StockIBM.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1ff23dc-cbbb-4452-b3c8-99aee15cbf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "[[0.5179317]]\n",
      "The stock price is 82.10252\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#load the model\n",
    "model = load_model('StockIBM.h5')\n",
    "user_input = [83.58746017, 80.34122742, 80.81285462, 82.00291895, 83.29159961, 81.44688209, 80.76357678, 83.80165525, 82.51120409, 82.48569342, 80.65383659, 81.69740582, 82.78338862, 83.37704145, 83.53829805, 80.20374715, 80.42476455, 82.69989097, 83.73417143, 82.95666579, 83.94381372, 82.37856671, 83.60787851, 81.80850007, 82.61239819, 82.06021048, 81.0673498, 83.7835985, 81.74964384, 83.10783276, 80.54146548, 80.49215929, 82.03237911, 81.79802128, 80.93914228, 83.90444224, 83.2143073, 81.31844381, 83.23807452, 83.4603476, 81.85039395, 81.3031393, 80.6351211, 83.65161771, 80.54893536, 82.22940581, 82.50289209, 80.59368723, 83.24620825, 81.77694404, 83.20275117, 83.43996357, 83.38335394, 82.69282925, 80.80822433, 80.30044039, 83.6842126, 82.82960781, 80.12425038, 82.25607533]\n",
    "\n",
    "user_input_array = np.array(user_input).reshape(-1, 1)\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "user_scaled = sc.fit_transform(user_input_array)\n",
    "user_scaled = user_scaled.reshape(1, 60, 1)\n",
    "\n",
    "pred = model.predict(user_scaled)\n",
    "print(pred)  # Changed pred(pred) to print(pred)\n",
    "#up-scale\n",
    "pred_original = sc.inverse_transform(pred)\n",
    "print(\"The stock price is\",pred_original[0][0]) #up scaled/original o/p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac371a7-d51a-4d3b-aa89-139431cd6be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
